"""Output formatter agent - generates comprehensive multi-format outputs."""

import json
import csv
from pathlib import Path
from typing import Dict, Any, List
from datetime import datetime
from agents.base_agent import BaseAgent
from models.state import BrandIntelligenceState
from utils.logger import get_logger
from utils.helpers import (
    generate_timestamp,
    sanitize_filename,
    load_json
)

logger = get_logger(__name__)


class OutputFormatterAgent(BaseAgent):
    """Agent responsible for generating comprehensive outputs in 8 formats."""

    def __init__(self):
        """Initialize the output formatter agent."""
        super().__init__("OutputFormatterAgent")
        self.output_dir = Path("output")
        self.output_dir.mkdir(exist_ok=True)

        # Load knowledge base
        kb_path = Path("data/iranian_brands_knowledge.json")
        self.knowledge_base = load_json(kb_path) if kb_path.exists() else {}

        if self.knowledge_base:
            logger.info("Loaded Iranian brands knowledge base")

    def execute(self, state: BrandIntelligenceState) -> BrandIntelligenceState:
        """Generate comprehensive outputs in 8 formats.

        Args:
            state: Current workflow state

        Returns:
            Updated state with output file paths
        """
        self._log_start()

        brand_name = state["brand_name"]
        timestamp = generate_timestamp()

        # Create brand-specific output directory
        safe_brand_name = sanitize_filename(brand_name)
        brand_output_dir = self.output_dir / safe_brand_name
        brand_output_dir.mkdir(exist_ok=True)

        # Enrich state with knowledge base if needed
        state = self._enrich_with_knowledge(state)

        # Generate all 9 output files
        output_files = {}

        try:
            logger.info(f"Generating 9 comprehensive output files for {brand_name}...")

            # 0. Complete Master Report (TXT)
            master_path = self._generate_master_report(state, brand_output_dir, timestamp)
            output_files["master_report"] = str(master_path)
            logger.info(f"[OK] Master Report: {master_path.name}")

            # 1. Brand Profile (JSON)
            profile_path = self._generate_brand_profile(state, brand_output_dir, timestamp)
            output_files["brand_profile"] = str(profile_path)
            logger.info(f"[OK] Brand Profile: {profile_path.name}")

            # 2. Strategic Insights (JSON)
            insights_path = self._generate_strategic_insights(state, brand_output_dir, timestamp)
            output_files["strategic_insights"] = str(insights_path)
            logger.info(f"[OK] Strategic Insights: {insights_path.name}")

            # 3. Brands Database (CSV)
            csv_path = self._generate_brands_database(state, brand_output_dir, timestamp)
            output_files["brands_database"] = str(csv_path)
            logger.info(f"[OK] Brands Database: {csv_path.name}")

            # 4. Embedding Ready (TXT)
            embedding_path = self._generate_embedding_text(state, brand_output_dir, timestamp)
            output_files["embedding_ready"] = str(embedding_path)
            logger.info(f"[OK] Embedding Ready: {embedding_path.name}")

            # 5. Financial Intelligence (JSON)
            financial_path = self._generate_financial_intelligence(state, brand_output_dir, timestamp)
            output_files["financial_intelligence"] = str(financial_path)
            logger.info(f"[OK] Financial Intelligence: {financial_path.name}")

            # 6. Executive Summary (MD)
            summary_path = self._generate_executive_summary(state, brand_output_dir, timestamp)
            output_files["executive_summary"] = str(summary_path)
            logger.info(f"[OK] Executive Summary: {summary_path.name}")

            # 7. Complete Product Catalog (JSON) - NEW!
            product_catalog_path = self._generate_product_catalog(state, brand_output_dir, timestamp)
            output_files["product_catalog"] = str(product_catalog_path)
            logger.info(f"[OK] Product Catalog: {product_catalog_path.name}")

            # 8. All Data Aggregated (TXT) - Combines ALL previous files
            aggregated_path = self._generate_all_data_aggregated(
                state,
                brand_output_dir,
                timestamp,
                output_files
            )
            output_files["all_data_aggregated"] = str(aggregated_path)
            logger.info(f"[OK] All Data Aggregated: {aggregated_path.name}")

            state["outputs"] = output_files
            self._log_end(success=True)

        except Exception as e:
            logger.error(f"Failed to generate outputs: {e}")
            import traceback
            traceback.print_exc()
            self._add_error(state, f"Output generation failed: {e}")
            state["outputs"] = output_files
            self._log_end(success=False)

        return state

    def _enrich_with_knowledge(self, state: BrandIntelligenceState) -> BrandIntelligenceState:
        """Enrich state data with knowledge base information."""
        brand_name = state["brand_name"]

        # Check if Active Cleaners
        if "active" in brand_name.lower() and "clean" in brand_name.lower():
            kb_data = self.knowledge_base.get("active_cleaners_detailed", {})
            if kb_data:
                logger.info("[KB] Enriching with Active Cleaners knowledge")

                # Enrich relationships if empty
                if not state.get("relationships", {}).get("parent_company"):
                    if "relationships" not in state:
                        state["relationships"] = {}
                    state["relationships"]["kb_enriched"] = True

        return state

    def _generate_master_report(self, state: Dict, output_dir: Path, timestamp: str) -> Path:
        """Generate complete master report (TXT) - 0_complete_master_report.txt"""
        output_path = output_dir / "0_complete_master_report.txt"

        brand_name = state["brand_name"]

        lines = []
        lines.append("=" * 80)
        lines.append(f"Ú¯Ø²Ø§Ø±Ø´ Ø¬Ø§Ù…Ø¹ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ù†Ø¯")
        lines.append(f"Ø¨Ø±Ù†Ø¯: {brand_name}")
        lines.append(f"ØªØ§Ø±ÛŒØ® ØªÙˆÙ„ÛŒØ¯: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"Ø´Ù†Ø§Ø³Ù‡ Ú¯Ø²Ø§Ø±Ø´: {timestamp}")
        lines.append("=" * 80)
        lines.append("")

        # Ø¨Ø®Ø´ Û±: Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ
        lines.append("Ø¨Ø®Ø´ Û±: Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ")
        lines.append("-" * 80)
        insights = state.get("insights", {})
        exec_summary = insights.get("executive_summary", "Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")
        lines.append(exec_summary)
        lines.append("")

        # Ø¨Ø®Ø´ Û²: Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø¨Ø±Ù†Ø¯
        lines.append("Ø¨Ø®Ø´ Û²: Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø¨Ø±Ù†Ø¯")
        lines.append("-" * 80)
        lines.append(f"Ù†Ø§Ù… Ø¨Ø±Ù†Ø¯: {brand_name}")
        lines.append(f"ÙˆØ¨Ø³Ø§ÛŒØª: {state.get('brand_website', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")

        structured = state.get("raw_data", {}).get("structured", {})
        website_info = structured.get("website_info", {})
        if website_info.get("title"):
            lines.append(f"Ø¹Ù†ÙˆØ§Ù† ÙˆØ¨Ø³Ø§ÛŒØª: {website_info['title']}")
        if website_info.get("meta_description"):
            lines.append(f"ØªÙˆØ¶ÛŒØ­Ø§Øª: {website_info['meta_description']}")
        lines.append("")

        # Ø¨Ø®Ø´ Û³: Ø³Ø§Ø®ØªØ§Ø± Ø´Ø±Ú©ØªÛŒ
        lines.append("Ø¨Ø®Ø´ Û³: Ø³Ø§Ø®ØªØ§Ø± Ø´Ø±Ú©ØªÛŒ Ùˆ Ø±ÙˆØ§Ø¨Ø·")
        lines.append("-" * 80)
        relationships = state.get("relationships", {})

        parent = relationships.get("parent_company", {})
        if parent and parent.get("name"):
            lines.append(f"Ø´Ø±Ú©Øª Ù…Ø§Ø¯Ø±: {parent.get('name')}")
            if parent.get("stock_symbol"):
                lines.append(f"Ù†Ù…Ø§Ø¯ Ø¨ÙˆØ±Ø³: {parent.get('stock_symbol')}")
            if parent.get("industry"):
                lines.append(f"ØµÙ†Ø¹Øª: {parent.get('industry')}")

        ultimate = relationships.get("ultimate_parent", {})
        if ultimate and ultimate.get("name"):
            lines.append(f"\nØ´Ø±Ú©Øª Ù…Ø§Ø¯Ø± Ù†Ù‡Ø§ÛŒÛŒ: {ultimate.get('name_fa', ultimate.get('name'))}")
            if ultimate.get("market_cap"):
                lines.append(f"Ø§Ø±Ø²Ø´ Ø¨Ø§Ø²Ø§Ø±: {ultimate.get('market_cap')}")
            if ultimate.get("total_brands"):
                lines.append(f"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø¨Ø±Ù†Ø¯Ù‡Ø§: {ultimate.get('total_brands')}")

        sister_brands = relationships.get("sister_brands", [])
        if sister_brands:
            lines.append(f"\nØ¨Ø±Ù†Ø¯Ù‡Ø§ÛŒ Ø®ÙˆØ§Ù‡Ø± ({len(sister_brands)}):")
            for brand in sister_brands[:10]:
                synergy = brand.get("synergy_score", "Ù†Ø§Ù…Ø´Ø®Øµ")
                lines.append(f"  - {brand.get('name')}: {brand.get('products', 'Ù†Ø§Ù…Ø´Ø®Øµ')} [Ù‡Ù…â€ŒØ§ÙØ²Ø§ÛŒÛŒ: {synergy}]")

        lines.append("")

        # Ø¨Ø®Ø´ Û´: Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§Ø²Ø§Ø±
        lines.append("Ø¨Ø®Ø´ Û´: Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§Ø²Ø§Ø±")
        lines.append("-" * 80)
        categorization = state.get("categorization", {})

        industry = categorization.get("primary_industry", {})
        if industry:
            lines.append(f"ØµÙ†Ø¹Øª: {industry.get('name_fa', industry.get('name_en', 'Ù†Ø§Ù…Ø´Ø®Øµ'))}")
            if industry.get("isic_code"):
                lines.append(f"Ú©Ø¯ ISIC: {industry.get('isic_code')}")

        if categorization.get("business_model"):
            lines.append(f"Ù…Ø¯Ù„ Ú©Ø³Ø¨â€ŒÙˆÚ©Ø§Ø±: {categorization['business_model']}")

        if categorization.get("price_tier"):
            lines.append(f"Ø³Ø·Ø­ Ù‚ÛŒÙ…ØªÛŒ: {categorization['price_tier']}")

        target_audiences = categorization.get("target_audiences", [])
        if target_audiences:
            lines.append(f"Ù…Ø®Ø§Ø·Ø¨Ø§Ù† Ù‡Ø¯Ù: {', '.join(target_audiences)}")

        channels = categorization.get("distribution_channels", [])
        if channels:
            lines.append(f"Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØªÙˆØ²ÛŒØ¹: {', '.join(channels)}")

        lines.append("")

        # Ø¨Ø®Ø´ Ûµ: Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ Ùˆ ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ©
        lines.append("Ø¨Ø®Ø´ Ûµ: Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ Ùˆ ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ©")
        lines.append("-" * 80)

        cross_promo = insights.get("cross_promotion_opportunities", [])
        if cross_promo:
            lines.append(f"ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ ØªØ¨Ù„ÛŒØºØ§Øª Ù…ØªÙ‚Ø§Ø¨Ù„ ({len(cross_promo)}):\n")
            for i, opp in enumerate(cross_promo, 1):
                lines.append(f"{i}. Ø¨Ø±Ù†Ø¯ Ø´Ø±ÛŒÚ©: {opp.get('partner_brand')}")
                lines.append(f"   Ù‡Ù…â€ŒØ§ÙØ²Ø§ÛŒÛŒ: {opp.get('synergy_level')} | Ø§ÙˆÙ„ÙˆÛŒØª: {opp.get('priority')}")
                lines.append(f"   Ø¨ÙˆØ¯Ø¬Ù‡: {opp.get('estimated_budget')}")
                lines.append(f"   Ù…ÙÙ‡ÙˆÙ… Ú©Ù…Ù¾ÛŒÙ†: {opp.get('campaign_concept')}")
                lines.append("")

        # Ø¨Ø®Ø´ Û¶: ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ù…Ù¾ÛŒÙ†
        lines.append("Ø¨Ø®Ø´ Û¶: ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ù…Ù¾ÛŒÙ†")
        lines.append("-" * 80)
        timing = insights.get("campaign_timing", {})

        optimal = timing.get("optimal_periods", [])
        if optimal:
            lines.append("Ø¯ÙˆØ±Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡:")
            for period in optimal:
                lines.append(f"  - {period}")

        avoid = timing.get("avoid_periods", [])
        if avoid:
            lines.append("\nØ¯ÙˆØ±Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬ØªÙ†Ø§Ø¨:")
            for period in avoid:
                lines.append(f"  - {period}")

        quarterly = timing.get("quarterly_recommendations", {})
        if quarterly:
            lines.append("\nØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ ÙØµÙ„ÛŒ:")
            for quarter, rec in quarterly.items():
                lines.append(f"  {quarter}: {rec}")

        lines.append("")

        # Ø¨Ø®Ø´ Û·: Ø¨ÙˆØ¯Ø¬Ù‡ Ùˆ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØªÙˆØµÛŒÙ‡â€ŒØ´Ø¯Ù‡
        lines.append("Ø¨Ø®Ø´ Û·: Ø¨ÙˆØ¯Ø¬Ù‡ Ùˆ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØªÙˆØµÛŒÙ‡â€ŒØ´Ø¯Ù‡")
        lines.append("-" * 80)
        budget = insights.get("budget_recommendations", {})

        if budget.get("estimated_range_tomans"):
            lines.append(f"Ø¨ÙˆØ¯Ø¬Ù‡ ØªØ®Ù…ÛŒÙ†ÛŒ: {budget['estimated_range_tomans']}")
        if budget.get("estimated_range_usd"):
            lines.append(f"Ù…Ø¹Ø§Ø¯Ù„ Ø¯Ù„Ø§Ø±: {budget['estimated_range_usd']}")

        allocation = budget.get("allocation_by_channel", {})
        if allocation:
            lines.append("\nØªØ®ØµÛŒØµ Ú©Ø§Ù†Ø§Ù„:")
            for channel, percent in allocation.items():
                lines.append(f"  - {channel}: {percent}")

        channel_recs = insights.get("channel_recommendations", [])
        if channel_recs:
            lines.append(f"\nØ¬Ø²Ø¦ÛŒØ§Øª Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ ({len(channel_recs)} Ú©Ø§Ù†Ø§Ù„):")
            for ch in channel_recs:
                lines.append(f"\n  {ch.get('channel')} - Ø§ÙˆÙ„ÙˆÛŒØª: {ch.get('priority')}")
                lines.append(f"  Ø¯Ù„ÛŒÙ„: {ch.get('rationale')}")
                lines.append(f"  Ø¨ÙˆØ¯Ø¬Ù‡: {ch.get('budget_allocation')}")

        lines.append("")

        # Ø¨Ø®Ø´ Û¸: Ø¬Ù‡Øªâ€ŒÚ¯ÛŒØ±ÛŒ Ø®Ù„Ø§Ù‚ÛŒØª
        lines.append("Ø¨Ø®Ø´ Û¸: Ø¬Ù‡Øªâ€ŒÚ¯ÛŒØ±ÛŒ Ø®Ù„Ø§Ù‚ÛŒØª")
        lines.append("-" * 80)
        creative = insights.get("creative_direction", {})

        messages = creative.get("key_messages", [])
        if messages:
            lines.append("Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ:")
            for msg in messages:
                lines.append(f"  - {msg}")

        if creative.get("tone_and_style"):
            lines.append(f"\nÙ„Ø­Ù† Ùˆ Ø³Ø¨Ú©: {creative['tone_and_style']}")

        if creative.get("visual_recommendations"):
            lines.append(f"ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨ØµØ±ÛŒ: {creative['visual_recommendations']}")

        hashtags = creative.get("hashtag_strategy", [])
        if hashtags:
            lines.append(f"\nØ§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù‡Ø´ØªÚ¯: {' '.join(hashtags)}")

        themes = creative.get("content_themes", [])
        if themes:
            lines.append("\nØªÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø­ØªÙˆØ§ÛŒÛŒ:")
            for theme in themes:
                lines.append(f"  - {theme}")

        lines.append("")

        # Ø¨Ø®Ø´ Û¹: Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…ÙˆÙÙ‚ÛŒØª Ùˆ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ
        lines.append("Ø¨Ø®Ø´ Û¹: Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…ÙˆÙÙ‚ÛŒØª Ùˆ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ")
        lines.append("-" * 80)
        metrics = insights.get("success_metrics", {})

        kpis = metrics.get("primary_kpis", [])
        if kpis:
            lines.append("Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø§ØµÙ„ÛŒ:")
            for kpi in kpis:
                lines.append(f"  - {kpi}")

        if metrics.get("measurement_approach"):
            lines.append(f"\nØ±ÙˆÛŒÚ©Ø±Ø¯ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ: {metrics['measurement_approach']}")

        if metrics.get("benchmarks"):
            lines.append(f"Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡: {metrics['benchmarks']}")

        lines.append("")
        lines.append("=" * 80)
        lines.append("Ù¾Ø§ÛŒØ§Ù† Ú¯Ø²Ø§Ø±Ø´")
        lines.append("=" * 80)

        # Write with UTF-8 encoding
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines))

        return output_path

    def _generate_brand_profile(self, state: Dict, output_dir: Path, timestamp: str) -> Path:
        """Generate brand profile JSON - 1_brand_profile.json"""
        output_path = output_dir / "1_brand_profile.json"

        brand_name = state["brand_name"]
        relationships = state.get("relationships", {})
        categorization = state.get("categorization", {})
        structured = state.get("raw_data", {}).get("structured", {})

        profile = {
            "brand_intelligence_report": {
                "generated_date": datetime.now().strftime("%Y-%m-%d"),
                "brand_id": f"{sanitize_filename(brand_name)}_{timestamp}",
                "data_sources": structured.get("sources_used", []),
                "report_version": "1.0"
            },
            "basic_information": {
                "brand_name": brand_name,
                "brand_name_persian": brand_name if any('\u0600' <= c <= '\u06FF' for c in brand_name) else "",
                "website": state.get("brand_website", ""),
                "establishment_year": "Unknown",
                "business_model": categorization.get("business_model", "B2C"),
                "service_type": categorization.get("primary_industry", {}).get("name_fa", "")
            },
            "parent_company_structure": {
                "immediate_parent": relationships.get("parent_company", {}),
                "ultimate_parent": relationships.get("ultimate_parent", {}),
                "ownership_chain": []
            },
            "brand_relationship_map": {
                "sister_brands_same_parent": relationships.get("sister_brands", []),
                "brand_family": relationships.get("brand_family", []),
                "total_related_brands": len(relationships.get("brand_family", []))
            },
            "product_categorization": {
                "primary_industry": categorization.get("primary_industry", {}),
                "sub_industries": categorization.get("sub_industries", []),
                "product_categories": categorization.get("product_categories", []),
                "service_categories": [],
                "customer_segments": {
                    "primary": categorization.get("target_audiences", []),
                    "secondary": []
                },
                "price_positioning": categorization.get("price_tier", "")
            },
            "market_intelligence": {
                "competitive_advantages": [],
                "market_position": categorization.get("market_position", {}),
                "distribution_channels": categorization.get("distribution_channels", [])
            },
            "contact_information": structured.get("contact_info", {}),
            "social_media_presence": structured.get("social_media", {}),
            "website_intelligence": structured.get("website_info", {})
        }

        # Write with UTF-8 encoding
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(profile, f, ensure_ascii=False, indent=2)

        return output_path

    def _generate_strategic_insights(self, state: Dict, output_dir: Path, timestamp: str) -> Path:
        """Generate strategic insights JSON - 2_strategic_insights.json"""
        output_path = output_dir / "2_strategic_insights.json"

        insights = state.get("insights", {})
        brand_name = state["brand_name"]

        strategic = {
            "strategic_intelligence_report": {
                "brand": brand_name,
                "generated_date": datetime.now().strftime("%Y-%m-%d"),
                "analyst": "Brand Intelligence Agent",
                "confidence_level": "high" if insights else "low"
            },
            "executive_summary": {
                "key_insight": insights.get("executive_summary", ""),
                "primary_opportunities": [opp.get("partner_brand", "") for opp in insights.get("cross_promotion_opportunities", [])[:3]]
            },
            "tier_1_opportunities": {
                "description": "High-priority, high-impact opportunities",
                "recommendations": [
                    {
                        "opportunity_id": f"ST-{str(i+1).zfill(3)}",
                        **opp
                    }
                    for i, opp in enumerate(insights.get("cross_promotion_opportunities", []))
                ]
            },
            "campaign_timing_recommendations": insights.get("campaign_timing", {}),
            "channel_strategy": {
                "recommendations": insights.get("channel_recommendations", []),
                "budget_allocation": insights.get("budget_recommendations", {}).get("allocation_by_channel", {})
            },
            "audience_intelligence": insights.get("audience_insights", {}),
            "competitive_strategy": insights.get("competitive_strategy", {}),
            "budget_allocation_recommendation": insights.get("budget_recommendations", {}),
            "creative_direction": insights.get("creative_direction", {}),
            "kpi_tracking": insights.get("success_metrics", {})
        }

        # Write with UTF-8 encoding
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(strategic, f, ensure_ascii=False, indent=2)

        return output_path

    def _get_category_hierarchy(self, category: str) -> Dict[str, str]:
        """Map category to 3-level hierarchy.

        Returns:
            Dict with category_level_1 (broad), category_level_2 (mid), category_level_3 (specific)
        """
        # Category hierarchy mapping (English-only with underscores)
        hierarchy_map = {
            # Technology Services
            "ride_hailing": {
                "level_1": "Technology_Services",
                "level_2": "On-Demand_Platforms",
                "level_3": "Ride-Hailing"
            },
            "food_delivery": {
                "level_1": "Technology_Services",
                "level_2": "On-Demand_Platforms",
                "level_3": "Food_Delivery"
            },
            "travel_technology": {
                "level_1": "Technology_Services",
                "level_2": "Travel_&_Hospitality",
                "level_3": "Online_Travel_Booking"
            },

            # Financial Services
            "insurance_technology": {
                "level_1": "Financial_Services",
                "level_2": "Insurance",
                "level_3": "Health_&_Auto_Insurance"
            },
            "fintech_payments": {
                "level_1": "Financial_Services",
                "level_2": "Fintech",
                "level_3": "Digital_Payments"
            },

            # Healthcare
            "telemedicine": {
                "level_1": "Healthcare_&_Life_Sciences",
                "level_2": "Digital_Health",
                "level_3": "Telemedicine"
            },
            "pharmaceutical": {
                "level_1": "Healthcare_&_Life_Sciences",
                "level_2": "Biopharmaceuticals",
                "level_3": "Biosimilar_Drugs"
            },
            "biotech": {
                "level_1": "Healthcare_&_Life_Sciences",
                "level_2": "Biotechnology",
                "level_3": "Biotech_Products"
            },

            # Transportation & Logistics
            "logistics_delivery": {
                "level_1": "Transportation_&_Logistics",
                "level_2": "Last-Mile_Delivery",
                "level_3": "Package_Delivery"
            },
            "transportation": {
                "level_1": "Transportation_&_Logistics",
                "level_2": "Mobility_Services",
                "level_3": "Ride_Services"
            },

            # Consumer Goods
            "cleaning_products": {
                "level_1": "Consumer_Goods",
                "level_2": "Home_Care",
                "level_3": "Dishwashing_&_Surface_Cleaners"
            },
            "laundry_care": {
                "level_1": "Consumer_Goods",
                "level_2": "Home_Care",
                "level_3": "Laundry_Detergents"
            },
            "dishwashing": {
                "level_1": "Consumer_Goods",
                "level_2": "Home_Care",
                "level_3": "Dishwashing_Products"
            },

            # Food & Beverage
            "confectionery_macaron": {
                "level_1": "Food_&_Beverage",
                "level_2": "Sweet_Snacks",
                "level_3": "Macarons_&_Cookies"
            },
            "confectionery": {
                "level_1": "Food_&_Beverage",
                "level_2": "Sweet_Snacks",
                "level_3": "Sweets_&_Confectionery"
            },
            "chocolate_manufacturing": {
                "level_1": "Food_&_Beverage",
                "level_2": "Sweet_Snacks",
                "level_3": "Chocolate_Products"
            },
            "food": {
                "level_1": "Food_&_Beverage",
                "level_2": "Packaged_Foods",
                "level_3": "Food_Products"
            },

            # Consumer Services
            "online_grocery": {
                "level_1": "Consumer_Services",
                "level_2": "E-Commerce",
                "level_3": "Online_Grocery"
            },
            "ecommerce": {
                "level_1": "Consumer_Services",
                "level_2": "E-Commerce",
                "level_3": "Online_Marketplace"
            },

            # Manufacturing
            "industrial_manufacturing": {
                "level_1": "Manufacturing",
                "level_2": "General_Manufacturing",
                "level_3": "Industrial_Products"
            }
        }

        # Get hierarchy or return defaults
        category_lower = category.lower().replace(" ", "_").replace("-", "_")
        hierarchy = hierarchy_map.get(category_lower, {
            "level_1": "Consumer_Products",
            "level_2": "General_Products",
            "level_3": category.replace(" ", "_").replace("-", "_")
        })

        return {
            "category_level_1": hierarchy["level_1"],
            "category_level_2": hierarchy["level_2"],
            "category_level_3": hierarchy["level_3"]
        }

    def _generate_brands_database(self, state: Dict, output_dir: Path, timestamp: str) -> Path:
        """Generate brands database CSV - 3_brands_database.csv"""
        output_path = output_dir / "3_brands_database.csv"

        relationships = state.get("relationships", {})
        brand_name = state["brand_name"]

        # Build brands list
        brands = []

        # Add current brand
        categorization = state.get("categorization", {})
        primary_industry = categorization.get("primary_industry", {})
        current_category = primary_industry.get("name_en", "Unknown")

        # Use category levels from categorization if available, otherwise derive from hierarchy map
        if "category_level_1" in primary_industry:
            current_hierarchy = {
                "category_level_1": primary_industry["category_level_1"],
                "category_level_2": primary_industry["category_level_2"],
                "category_level_3": primary_industry["category_level_3"]
            }
        else:
            current_hierarchy = self._get_category_hierarchy(current_category)

        brands.append({
            "brand_name": brand_name,
            "parent_company": relationships.get("parent_company", {}).get("name", "Unknown"),
            "category": current_category,
            "category_level_1": current_hierarchy["category_level_1"],
            "category_level_2": current_hierarchy["category_level_2"],
            "category_level_3": current_hierarchy["category_level_3"],
            "cross_sell_potential": "SELF",
            "market_position": "Unknown",
            "price_tier": state.get("categorization", {}).get("price_tier", "Unknown")
        })

        # Add sister brands
        for brand in relationships.get("sister_brands", []):
            brand_category = brand.get("category", "Unknown")
            brand_hierarchy = self._get_category_hierarchy(brand_category)

            brands.append({
                "brand_name": brand.get("name"),
                "parent_company": relationships.get("parent_company", {}).get("name", "Unknown"),
                "category": brand_category,
                "category_level_1": brand_hierarchy["category_level_1"],
                "category_level_2": brand_hierarchy["category_level_2"],
                "category_level_3": brand_hierarchy["category_level_3"],
                "cross_sell_potential": brand.get("synergy_score", "MEDIUM"),
                "market_position": "Strong",
                "price_tier": brand.get("price_tier", "Unknown")
            })

        # Add brand family
        for brand in relationships.get("brand_family", []):
            brand_category = brand.get("category", "Unknown")
            brand_hierarchy = self._get_category_hierarchy(brand_category)

            brands.append({
                "brand_name": brand.get("name"),
                "parent_company": brand.get("parent", "Unknown"),
                "category": brand_category,
                "category_level_1": brand_hierarchy["category_level_1"],
                "category_level_2": brand_hierarchy["category_level_2"],
                "category_level_3": brand_hierarchy["category_level_3"],
                "cross_sell_potential": "LOW",
                "market_position": "Unknown",
                "price_tier": "Unknown"
            })

        # Write CSV with UTF-8 encoding
        if brands:
            with open(output_path, 'w', newline='', encoding='utf-8-sig') as f:  # utf-8-sig for Excel compatibility
                fieldnames = [
                    "brand_name",
                    "parent_company",
                    "category",
                    "category_level_1",
                    "category_level_2",
                    "category_level_3",
                    "cross_sell_potential",
                    "market_position",
                    "price_tier"
                ]
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(brands)

        return output_path

    def _generate_embedding_text(self, state: Dict, output_dir: Path, timestamp: str) -> Path:
        """Generate embedding-ready text - 4_embedding_ready.txt (2500+ words)"""
        output_path = output_dir / "4_embedding_ready.txt"

        brand_name = state["brand_name"]
        relationships = state.get("relationships", {})
        categorization = state.get("categorization", {})
        insights = state.get("insights", {})
        structured = state.get("raw_data", {}).get("structured", {})

        lines = []

        # Ù…Ù‚Ø¯Ù…Ù‡
        lines.append(f"Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø¨Ø±Ù†Ø¯: {brand_name}")
        lines.append("")
        lines.append("Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø§ÛŒÙ‡")
        lines.append(f"{brand_name} ÛŒÚ© Ø¨Ø±Ù†Ø¯ ÙØ¹Ø§Ù„ Ø¯Ø± ØµÙ†Ø¹Øª {categorization.get('primary_industry', {}).get('name_fa', 'Ø¨Ø§Ø²Ø§Ø± Ù…ØµØ±Ùâ€ŒÚ©Ù†Ù†Ø¯Ù‡')} Ø§Ø³Øª.")

        parent = relationships.get("parent_company", {})
        if parent and parent.get("name"):
            lines.append(f"Ø§ÛŒÙ† Ø¨Ø±Ù†Ø¯ Ù…ØªØ¹Ù„Ù‚ Ø¨Ù‡ {parent.get('name')} Ø§Ø³Øª Ú©Ù‡ Ø¨Ø§ Ù†Ù…Ø§Ø¯ Ø¨ÙˆØ±Ø³ {parent.get('stock_symbol', 'Ù†Ø§Ù…Ø´Ø®Øµ')} ÙØ¹Ø§Ù„ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯.")

        ultimate = relationships.get("ultimate_parent", {})
        if ultimate and ultimate.get("name"):
            lines.append(f"Ø´Ø±Ú©Øª Ù…Ø§Ø¯Ø± Ù†Ù‡Ø§ÛŒÛŒ {ultimate.get('name_fa', ultimate.get('name'))} Ø§Ø³ØªØŒ ")
            lines.append(f"ÛŒÚ©ÛŒ Ø§Ø² Ø¨Ø²Ø±Ú¯ØªØ±ÛŒÙ† Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ ØµÙ†Ø¹ØªÛŒ Ø§ÛŒØ±Ø§Ù† Ø¨Ø§ {ultimate.get('total_brands', 'Ú†Ù†Ø¯ÛŒÙ†')} Ø¨Ø±Ù†Ø¯ ")
            lines.append(f"Ùˆ Ø§Ø±Ø²Ø´ Ø¨Ø§Ø²Ø§Ø± ØªØ®Ù…ÛŒÙ†ÛŒ {ultimate.get('market_cap', 'Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡')}.")

        lines.append("")

        # Ø³Ø§Ø®ØªØ§Ø± Ø´Ø±Ú©ØªÛŒ
        lines.append("Ø³Ø§Ø®ØªØ§Ø± Ø´Ø±Ú©ØªÛŒ")
        lines.append(f"Ø³Ø§Ø®ØªØ§Ø± Ø´Ø±Ú©ØªÛŒ {brand_name} Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ ÛŒÚ© Ø³Ù„Ø³Ù„Ù‡â€ŒÙ…Ø±Ø§ØªØ¨ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø§Ø² Ù…Ø§Ù„Ú©ÛŒØª Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø¨Ø±Ù†Ø¯ Ø§Ø³Øª.")

        if parent:
            lines.append(f"Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ© Ø´Ø±Ú©Øª ØªØ§Ø¨Ø¹Ù‡ Ù…Ø³ØªÙ‚ÛŒÙ… {parent.get('name')}ØŒ Ø§ÛŒÙ† Ø¨Ø±Ù†Ø¯ Ø§Ø² Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙˆØ²ÛŒØ¹ Ù…Ø³ØªÙ‚Ø±ØŒ ")
            lines.append(f"ØªØ®ØµØµ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ Ùˆ Ø«Ø¨Ø§Øª Ù…Ø§Ù„ÛŒ Ø¨Ù‡Ø±Ù‡â€ŒÙ…Ù†Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ø´Ø±Ú©Øª Ù…Ø§Ø¯Ø± Ø¯Ø± Ø¨Ø®Ø´ {parent.get('industry', 'Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ØµØ±ÙÛŒ')} ÙØ¹Ø§Ù„ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ")
            lines.append("Ùˆ Ù‡Ù…â€ŒØ±Ø§Ø³ØªØ§ÛŒÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ© Ùˆ Ù‡Ù…â€ŒØ§ÙØ²Ø§ÛŒÛŒ Ø±Ø§ Ø¯Ø± Ø³Ø¨Ø¯ Ø¨Ø±Ù†Ø¯Ù‡Ø§ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒØ¢ÙˆØ±Ø¯.")

        lines.append("")

        # Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡ Ø¨Ø±Ù†Ø¯
        lines.append("Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡ Ø¨Ø±Ù†Ø¯ - Ø¨Ø±Ù†Ø¯Ù‡Ø§ÛŒ Ø®ÙˆØ§Ù‡Ø±")
        sister_brands = relationships.get("sister_brands", [])
        if sister_brands:
            lines.append(f"{brand_name} Ø¨Ø®Ø´ÛŒ Ø§Ø² Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡â€ŒØ§ÛŒ Ù…ØªØ´Ú©Ù„ Ø§Ø² {len(sister_brands)} Ø¨Ø±Ù†Ø¯ Ø®ÙˆØ§Ù‡Ø± ØªØ­Øª Ø´Ø±Ú©Øª Ù…Ø§Ø¯Ø± ÛŒÚ©Ø³Ø§Ù† Ø§Ø³Øª.")
            lines.append("Ø§ÛŒÙ† Ø¨Ø±Ù†Ø¯Ù‡Ø§ÛŒ Ø®ÙˆØ§Ù‡Ø± ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¨Ù„ÛŒØºØ§Øª Ù…ØªÙ‚Ø§Ø¨Ù„ Ùˆ Ø¨Ø§Ø²Ø§Ø±ÛŒØ§Ø¨ÛŒ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯:")
            lines.append("")

            for brand in sister_brands:
                lines.append(f"- {brand.get('name')}: ØªØ®ØµØµ Ø¯Ø± {brand.get('products', 'Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ØµØ±ÙÛŒ')}ØŒ ")
                lines.append(f"  Ù‡Ø¯Ùâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø¨Ù‡ {brand.get('target_audience', 'Ù…ØµØ±Ùâ€ŒÚ©Ù†Ù†Ø¯Ú¯Ø§Ù† Ø¹Ù…ÙˆÙ…ÛŒ')} Ø¨Ø§ Ø§Ù…ØªÛŒØ§Ø² Ù‡Ù…â€ŒØ§ÙØ²Ø§ÛŒÛŒ {brand.get('synergy_score', 'Ù…ØªÙˆØ³Ø·')}.")
                lines.append(f"  Ø§ÛŒÙ† Ø¨Ø±Ù†Ø¯ Ø¯Ø± Ø¯Ø³ØªÙ‡ {brand.get('category', 'Ù…ØµØ±ÙÛŒ')} Ø¨Ø§ Ù‚ÛŒÙ…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ {brand.get('price_tier', 'Ù…ØªÙˆØ³Ø·')} ÙØ¹Ø§Ù„ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯.")
                lines.append("")

        brand_family = relationships.get("brand_family", [])
        if brand_family:
            lines.append(f"Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡ Ú¯Ø³ØªØ±Ø¯Ù‡â€ŒØªØ± Ø¨Ø±Ù†Ø¯ Ø´Ø§Ù…Ù„ {len(brand_family)} Ø¨Ø±Ù†Ø¯ Ø¯Ø± Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù…ØªØ¹Ø¯Ø¯ Ø§Ø³Øª:")
            for brand in brand_family[:15]:
                lines.append(f"- {brand.get('name')} (Ø¯Ø³ØªÙ‡ {brand.get('category', 'Ù…ØµØ±ÙÛŒ')}) ØªØ­Øª {brand.get('parent', 'Ù…Ø¯ÛŒØ±ÛŒØª Ú¯Ø±ÙˆÙ‡')}")
            lines.append("")

        # Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÛŒØ§Ø¨ÛŒ Ø¨Ø§Ø²Ø§Ø±
        lines.append("Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÛŒØ§Ø¨ÛŒ Ø¨Ø§Ø²Ø§Ø±")
        lines.append(f"{brand_name} Ø¨Ø§ Ù…Ø¯Ù„ Ú©Ø³Ø¨â€ŒÙˆÚ©Ø§Ø± {categorization.get('business_model', 'B2C')} ÙØ¹Ø§Ù„ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ ")
        lines.append(f"Ø¨Ø§ Ù‡Ø¯Ùâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø¨Ù‡ {', '.join(categorization.get('target_audiences', ['Ù…ØµØ±Ùâ€ŒÚ©Ù†Ù†Ø¯Ú¯Ø§Ù† Ø¹Ù…ÙˆÙ…ÛŒ']))}.")
        lines.append(f"Ø§ÛŒÙ† Ø¨Ø±Ù†Ø¯ Ø¯Ø± Ø³Ø·Ø­ Ù‚ÛŒÙ…ØªÛŒ {categorization.get('price_tier', 'Ù…ØªÙˆØ³Ø·')} Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯ ")
        lines.append("Ùˆ Ø¨ÛŒÙ† Ú©ÛŒÙÛŒØª Ùˆ Ù…Ù‚Ø±ÙˆÙ†â€ŒØ¨Ù‡â€ŒØµØ±ÙÙ‡ Ø¨ÙˆØ¯Ù† ØªØ¹Ø§Ø¯Ù„ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø³Ù‡Ù… Ø¨Ø§Ø²Ø§Ø± Ø±Ø§ Ø¨Ù‡ Ø¯Ø³Øª Ø¢ÙˆØ±Ø¯.")
        lines.append("")

        market_pos = categorization.get("market_position", {})
        if market_pos:
            lines.append(f"Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¨Ø§Ø²Ø§Ø±: {market_pos.get('positioning', 'Ø±Ù‚Ø§Ø¨ØªÛŒ')}.")
            lines.append(f"Ú†Ø´Ù…â€ŒØ§Ù†Ø¯Ø§Ø² Ø±Ù‚Ø§Ø¨ØªÛŒ: {market_pos.get('competitive_landscape', 'Ù¾ÙˆÛŒØ§ Ùˆ Ø±Ù‚Ø§Ø¨ØªÛŒ')}.")

        channels = categorization.get("distribution_channels", [])
        if channels:
            lines.append(f"Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØªÙˆØ²ÛŒØ¹ Ø´Ø§Ù…Ù„ {', '.join(channels)} Ø§Ø³ØªØŒ ")
            lines.append("Ú©Ù‡ Ù¾ÙˆØ´Ø´ Ú¯Ø³ØªØ±Ø¯Ù‡ Ø¨Ø§Ø²Ø§Ø± Ùˆ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ØµØ±Ùâ€ŒÚ©Ù†Ù†Ø¯Ú¯Ø§Ù† Ù‡Ø¯Ù Ø±Ø§ ØªØ¶Ù…ÛŒÙ† Ù…ÛŒâ€ŒÚ©Ù†Ø¯.")
        lines.append("")

        # ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ©
        lines.append("ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ©")
        cross_promo = insights.get("cross_promotion_opportunities", [])
        if cross_promo:
            lines.append(f"ØªØ­Ù„ÛŒÙ„ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ {len(cross_promo)} ÙØ±ØµØª Ø¨Ø§ Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø¨Ø§Ù„Ø§ Ø¨Ø±Ø§ÛŒ ØªØ¨Ù„ÛŒØºØ§Øª Ù…ØªÙ‚Ø§Ø¨Ù„:")
            lines.append("")

            for i, opp in enumerate(cross_promo, 1):
                lines.append(f"{i}. Ù‡Ù…Ú©Ø§Ø±ÛŒ Ø¨Ø§ {opp.get('partner_brand')}")
                lines.append(f"   Ø³Ø·Ø­ Ù‡Ù…â€ŒØ§ÙØ²Ø§ÛŒÛŒ: {opp.get('synergy_level')}")
                lines.append(f"   Ù…ÙÙ‡ÙˆÙ… Ú©Ù…Ù¾ÛŒÙ†: {opp.get('campaign_concept')}")
                lines.append(f"   Ù…Ø®Ø§Ø·Ø¨ Ù‡Ø¯Ù: {opp.get('target_audience')}")
                lines.append(f"   Ø¨ÙˆØ¯Ø¬Ù‡ ØªØ®Ù…ÛŒÙ†ÛŒ: {opp.get('estimated_budget')}")
                lines.append(f"   Ù…Ù†Ø§ÙØ¹ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: {opp.get('expected_benefit')}")
                lines.append(f"   Ø³Ø®ØªÛŒ Ø§Ø¬Ø±Ø§: {opp.get('implementation_difficulty')}")
                lines.append("")

        # ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ù…Ù¾ÛŒÙ†
        lines.append("ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ù…Ù¾ÛŒÙ†")
        timing = insights.get("campaign_timing", {})
        optimal = timing.get("optimal_periods", [])
        if optimal:
            lines.append("Ø¯ÙˆØ±Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ú©Ù…Ù¾ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ£Ø«ÛŒØ±:")
            for period in optimal:
                lines.append(f"- {period}: ØªØ¹Ø§Ù…Ù„ Ùˆ Ù‡Ø²ÛŒÙ†Ù‡ Ø¨Ø§Ù„Ø§ÛŒ Ù…ØµØ±Ùâ€ŒÚ©Ù†Ù†Ø¯Ù‡")
            lines.append("")

        avoid = timing.get("avoid_periods", [])
        if avoid:
            lines.append("Ø¯ÙˆØ±Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø§Ø² Ú©Ù…Ù¾ÛŒÙ†â€ŒÙ‡Ø§ÛŒ ØªØ¬Ø§Ø±ÛŒ Ø§Ø¬ØªÙ†Ø§Ø¨ Ú©Ø±Ø¯:")
            for period in avoid:
                lines.append(f"- {period}")
            lines.append("")

        # ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨ÙˆØ¯Ø¬Ù‡
        lines.append("ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨ÙˆØ¯Ø¬Ù‡ Ùˆ Ø³Ø±Ù…Ø§ÛŒÙ‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ")
        budget = insights.get("budget_recommendations", {})
        if budget:
            lines.append(f"Ø¨ÙˆØ¯Ø¬Ù‡ ØªØ¨Ù„ÛŒØºØ§ØªÛŒ Ø³Ø§Ù„Ø§Ù†Ù‡ ØªÙˆØµÛŒÙ‡â€ŒØ´Ø¯Ù‡: {budget.get('estimated_range_tomans', '500M-1B ØªÙˆÙ…Ø§Ù†')}")
            lines.append(f"Ù…Ø¹Ø§Ø¯Ù„ Ø¯Ù„Ø§Ø±: {budget.get('estimated_range_usd', '$10K-$20K')}")
            lines.append(f"Ø¨Ø§Ø²Ø¯Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± Ø³Ø±Ù…Ø§ÛŒÙ‡: {budget.get('roi_expectations', '2-3 Ø¨Ø±Ø§Ø¨Ø± Ø¯Ø± 6 Ù…Ø§Ù‡')}")
            lines.append("")

            allocation = budget.get("allocation_by_channel", {})
            if allocation:
                lines.append("ØªØ®ØµÛŒØµ Ú©Ø§Ù†Ø§Ù„ ØªÙˆØµÛŒÙ‡â€ŒØ´Ø¯Ù‡:")
                for channel, percent in allocation.items():
                    lines.append(f"- {channel}: {percent}")
                lines.append("")

        # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±ÛŒØ§Ø¨ÛŒ
        lines.append("Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±ÛŒØ§Ø¨ÛŒ")
        channel_recs = insights.get("channel_recommendations", [])
        if channel_recs:
            for ch in channel_recs:
                lines.append(f"{ch.get('channel')} (Ø§ÙˆÙ„ÙˆÛŒØª: {ch.get('priority')})")
                lines.append(f"  Ø¯Ù„ÛŒÙ„: {ch.get('rationale')}")
                lines.append(f"  Ù†ÙˆØ¹ Ù…Ø­ØªÙˆØ§: {ch.get('content_type', 'Ù…Ø­ØªÙˆØ§ÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ')}")
                lines.append(f"  ØªØ®ØµÛŒØµ Ø¨ÙˆØ¯Ø¬Ù‡: {ch.get('budget_allocation', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
                lines.append("")

        # Ø¬Ù‡Øªâ€ŒÚ¯ÛŒØ±ÛŒ Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡
        lines.append("Ø¬Ù‡Øªâ€ŒÚ¯ÛŒØ±ÛŒ Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡ Ùˆ Ù¾ÛŒØ§Ù…â€ŒØ±Ø³Ø§Ù†ÛŒ")
        creative = insights.get("creative_direction", {})
        if creative:
            messages = creative.get("key_messages", [])
            if messages:
                lines.append("Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ù†Ø¯:")
                for msg in messages:
                    lines.append(f"- {msg}")
                lines.append("")

            lines.append(f"Ù„Ø­Ù† Ùˆ Ø³Ø¨Ú©: {creative.get('tone_and_style', 'Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ø¬Ø°Ø§Ø¨')}")
            lines.append(f"ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨ØµØ±ÛŒ: {creative.get('visual_recommendations', 'Ø·Ø±Ø§Ø­ÛŒ ØªÙ…ÛŒØ² Ùˆ Ù…Ø¯Ø±Ù†')}")
            lines.append(f"Ù…Ù„Ø§Ø­Ø¸Ø§Øª ÙØ±Ù‡Ù†Ú¯ÛŒ: {creative.get('cultural_considerations', 'Ø§Ø­ØªØ±Ø§Ù… Ø¨Ù‡ Ø§Ø±Ø²Ø´â€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ')}")
            lines.append("")

        # Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…ÙˆÙÙ‚ÛŒØª
        lines.append("Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…ÙˆÙÙ‚ÛŒØª Ùˆ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ")
        metrics = insights.get("success_metrics", {})
        kpis = metrics.get("primary_kpis", [])
        if kpis:
            lines.append("Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ù…ÙˆÙÙ‚ÛŒØª Ú©Ù…Ù¾ÛŒÙ†:")
            for kpi in kpis:
                lines.append(f"- {kpi}")
            lines.append("")

        lines.append(f"Ø±ÙˆÛŒÚ©Ø±Ø¯ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ: {metrics.get('measurement_approach', 'Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ùˆ Ú¯Ø²Ø§Ø±Ø´â€ŒØ¯Ù‡ÛŒ Ù…Ø§Ù‡Ø§Ù†Ù‡')}")
        lines.append(f"Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡: {metrics.get('benchmarks', 'Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ ØµÙ†Ø¹Øª Ùˆ Ø¹Ù…Ù„Ú©Ø±Ø¯ ØªØ§Ø±ÛŒØ®ÛŒ')}")

        # Write with UTF-8 encoding
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines))

        return output_path

    def _generate_financial_intelligence(self, state: Dict, output_dir: Path, timestamp: str) -> Path:
        """Generate financial intelligence JSON - 5_financial_intelligence.json"""
        output_path = output_dir / "5_financial_intelligence.json"

        relationships = state.get("relationships", {})
        categorization = state.get("categorization", {})

        parent = relationships.get("parent_company", {})
        ultimate = relationships.get("ultimate_parent", {})

        financial = {
            "financial_intelligence_report": {
                "report_date": datetime.now().strftime("%Y-%m-%d"),
                "data_sources": ["Parent company disclosures", "Market estimates", "Industry analysis"],
                "confidence_level": "medium"
            },
            "parent_company_overview": {
                "name": parent.get("name", "Unknown"),
                "stock_symbol": parent.get("stock_symbol", "N/A"),
                "market": "Tehran Stock Exchange" if parent.get("stock_symbol") else "Private",
                "industry": parent.get("industry", "Unknown")
            },
            "ownership_structure": {
                "immediate_parent": parent.get("name", "Unknown"),
                "ultimate_parent": ultimate.get("name_fa", "Unknown"),
                "ownership_percentage": ultimate.get("ownership_percentage", "Unknown"),
                "public_float": "Unknown"
            },
            "market_capitalization": {
                "estimate": ultimate.get("market_cap", "Unknown"),
                "currency": "Iranian Toman",
                "calculation_method": "Industry estimates"
            },
            "advertising_intelligence_framework": {
                "industry_standards": "2-5% of revenue for FMCG",
                "competitive_benchmarks": "Leading brands invest 3-7% of revenue",
                "recommended_range": categorization.get("price_tier", "mid") + " tier: 2-4% of estimated revenue"
            },
            "estimated_advertising_budget": {
                "annual_estimate_tomans": "500M-1B Tomans",
                "annual_estimate_usd": "$10K-$20K",
                "basis": "Industry standards and price tier positioning",
                "confidence": "medium"
            }
        }

        # Write with UTF-8 encoding
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(financial, f, ensure_ascii=False, indent=2)

        return output_path

    def _generate_executive_summary(self, state: Dict, output_dir: Path, timestamp: str) -> Path:
        """Generate executive summary MD - 6_executive_summary.md (1800+ words)"""
        output_path = output_dir / "6_executive_summary.md"

        brand_name = state["brand_name"]
        relationships = state.get("relationships", {})
        categorization = state.get("categorization", {})
        insights = state.get("insights", {})
        structured = state.get("raw_data", {}).get("structured", {})

        lines = []

        # Ø³Ø±ØµÙØ­Ù‡
        lines.append(f"# Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ù†Ø¯: {brand_name}")
        lines.append("")
        lines.append("## Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ")
        lines.append("")
        lines.append(f"**ØªØ§Ø±ÛŒØ® Ú¯Ø²Ø§Ø±Ø´:** {datetime.now().strftime('%Y-%m-%d')}")
        lines.append(f"**Ø¨Ø±Ù†Ø¯:** {brand_name}")
        lines.append(f"**ØµÙ†Ø¹Øª:** {categorization.get('primary_industry', {}).get('name_fa', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
        lines.append(f"**Ù…Ø¯Ù„ Ú©Ø³Ø¨â€ŒÙˆÚ©Ø§Ø±:** {categorization.get('business_model', 'B2C')}")
        lines.append("")
        lines.append("---")
        lines.append("")

        # Ø®Ù„Ø§ØµÙ‡ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ©
        lines.append("## ğŸ¯ Ø®Ù„Ø§ØµÙ‡ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ©")
        lines.append("")
        exec_summary = insights.get("executive_summary", "")
        if exec_summary:
            lines.append(exec_summary)
        else:
            lines.append(f"{brand_name} Ù†Ù…Ø§ÛŒÙ†Ø¯Ù‡ ÛŒÚ© ÙØ±ØµØª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ© Ø¯Ø± Ø¨Ø§Ø²Ø§Ø± {categorization.get('primary_industry', {}).get('name_fa', 'Ù…ØµØ±ÙÛŒ')} Ø§ÛŒØ±Ø§Ù† Ø§Ø³Øª.")
        lines.append("")
        lines.append("---")
        lines.append("")

        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„ÛŒ Ø¨Ø±Ù†Ø¯
        lines.append("## ğŸ“Š Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„ÛŒ Ø¨Ø±Ù†Ø¯")
        lines.append("")
        lines.append("### Ù‡ÙˆÛŒØª Ø¨Ø±Ù†Ø¯")
        lines.append("")
        lines.append(f"- **Ù†Ø§Ù… Ø¨Ø±Ù†Ø¯:** {brand_name}")
        website = state.get("brand_website", "")
        if website:
            lines.append(f"- **ÙˆØ¨Ø³Ø§ÛŒØª:** [{website}]({website})")

        parent = relationships.get("parent_company", {})
        if parent and parent.get("name"):
            lines.append(f"- **Ø´Ø±Ú©Øª Ù…Ø§Ø¯Ø±:** {parent.get('name')}")
            if parent.get("stock_symbol"):
                lines.append(f"- **Ù†Ù…Ø§Ø¯ Ø¨ÙˆØ±Ø³:** {parent.get('stock_symbol')}")

        ultimate = relationships.get("ultimate_parent", {})
        if ultimate and ultimate.get("name"):
            lines.append(f"- **Ø´Ø±Ú©Øª Ù…Ø§Ø¯Ø± Ù†Ù‡Ø§ÛŒÛŒ:** {ultimate.get('name_fa', ultimate.get('name'))}")

        lines.append("")

        website_info = structured.get("website_info", {})
        if website_info.get("title"):
            lines.append(f"**Ø¹Ù†ÙˆØ§Ù† ÙˆØ¨Ø³Ø§ÛŒØª:** {website_info['title']}")
            lines.append("")

        if website_info.get("meta_description"):
            lines.append(f"**ØªÙˆØ¶ÛŒØ­Ø§Øª:** {website_info['meta_description']}")
            lines.append("")

        # Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¨Ø§Ø²Ø§Ø±
        lines.append("### Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÛŒØ§Ø¨ÛŒ Ø¨Ø§Ø²Ø§Ø±")
        lines.append("")
        lines.append(f"- **ØµÙ†Ø¹Øª:** {categorization.get('primary_industry', {}).get('name_fa', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
        lines.append(f"- **Ø³Ø·Ø­ Ù‚ÛŒÙ…ØªÛŒ:** {categorization.get('price_tier', 'Ù†Ø§Ù…Ø´Ø®Øµ').replace('_', ' ').title()}")

        target_audiences = categorization.get("target_audiences", [])
        if target_audiences:
            lines.append(f"- **Ù…Ø®Ø§Ø·Ø¨ Ù‡Ø¯Ù:** {', '.join(target_audiences).replace('_', ' ').title()}")

        channels = categorization.get("distribution_channels", [])
        if channels:
            lines.append(f"- **Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØªÙˆØ²ÛŒØ¹:** {', '.join(channels).title()}")

        lines.append("")
        lines.append("---")
        lines.append("")

        # Ø³Ø§Ø®ØªØ§Ø± Ø´Ø±Ú©ØªÛŒ
        lines.append("## ğŸ¢ Ø³Ø§Ø®ØªØ§Ø± Ø´Ø±Ú©ØªÛŒ")
        lines.append("")

        if parent:
            lines.append("### Ø´Ø±Ú©Øª Ù…Ø§Ø¯Ø±")
            lines.append("")
            lines.append(f"**{parent.get('name')}** Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø´Ø±Ú©Øª Ù…Ø§Ø¯Ø± Ù…Ø³ØªÙ‚ÛŒÙ…ØŒ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø±Ø§ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯:")
            lines.append("")
            lines.append("- Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…Ø§Ù„ÛŒ Ùˆ Ø«Ø¨Ø§Øª")
            lines.append("- Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙˆØ²ÛŒØ¹ Ù…Ø³ØªÙ‚Ø±")
            lines.append("- ØªØ®ØµØµ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ Ùˆ Ø¨Ù‡ØªØ±ÛŒÙ† Ø´ÛŒÙˆÙ‡â€ŒÙ‡Ø§")
            lines.append(f"- Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø²ÛŒØ±Ø³Ø§Ø®Øª Ø¨Ø§Ø²Ø§Ø± {parent.get('industry', 'Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ØµØ±ÙÛŒ')}")
            lines.append("")

        if ultimate:
            lines.append("### Ú¯Ø±ÙˆÙ‡ Ù…Ø§Ø¯Ø± Ù†Ù‡Ø§ÛŒÛŒ")
            lines.append("")
            lines.append(f"**{ultimate.get('name_fa', ultimate.get('name'))}** Ù†Ù…Ø§ÛŒÙ†Ø¯Ù‡ Ø³Ø§Ø²Ù…Ø§Ù† Ù…Ø§Ø¯Ø± Ù†Ù‡Ø§ÛŒÛŒ Ø§Ø³Øª:")
            lines.append("")
            if ultimate.get("description"):
                lines.append(f"- {ultimate['description']}")
            if ultimate.get("market_cap"):
                lines.append(f"- Ø§Ø±Ø²Ø´ Ø¨Ø§Ø²Ø§Ø±: {ultimate['market_cap']}")
            if ultimate.get("total_brands"):
                lines.append(f"- Ø³Ø¨Ø¯ Ø¨Ø±Ù†Ø¯Ù‡Ø§: {ultimate['total_brands']} Ø¨Ø±Ù†Ø¯")
            if ultimate.get("employees"):
                lines.append(f"- Ù†ÛŒØ±ÙˆÛŒ Ú©Ø§Ø±: {ultimate['employees']} Ú©Ø§Ø±Ù…Ù†Ø¯")
            lines.append("")

        lines.append("---")
        lines.append("")

        # Ø¨Ø±Ù†Ø¯Ù‡Ø§ÛŒ Ø®ÙˆØ§Ù‡Ø±
        lines.append("## ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡ Ø¨Ø±Ù†Ø¯ Ùˆ Ø±ÙˆØ§Ø¨Ø·")
        lines.append("")

        sister_brands = relationships.get("sister_brands", [])
        if sister_brands:
            lines.append(f"### Ø¨Ø±Ù†Ø¯Ù‡Ø§ÛŒ Ø®ÙˆØ§Ù‡Ø± ({len(sister_brands)} Ø¨Ø±Ù†Ø¯)")
            lines.append("")
            lines.append(f"{brand_name} Ø´Ø±Ú©Øª Ù…Ø§Ø¯Ø± Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø§ {len(sister_brands)} Ø¨Ø±Ù†Ø¯ Ø®ÙˆØ§Ù‡Ø± Ø¨Ù‡ Ø§Ø´ØªØ±Ø§Ú© Ù…ÛŒâ€ŒÚ¯Ø°Ø§Ø±Ø¯ØŒ")
            lines.append("Ú©Ù‡ ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¨Ù„ÛŒØºØ§Øª Ù…ØªÙ‚Ø§Ø¨Ù„ Ùˆ Ø¨Ø§Ø²Ø§Ø±ÛŒØ§Ø¨ÛŒ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯:")
            lines.append("")

            for brand in sister_brands:
                synergy = brand.get("synergy_score", "MEDIUM")
                synergy_emoji = {"VERY_HIGH": "â­â­â­", "HIGH": "â­â­", "MEDIUM": "â­", "LOW": "â—‹"}.get(synergy, "â—‹")

                lines.append(f"#### {brand.get('name')} {synergy_emoji}")
                lines.append("")
                lines.append(f"- **Ù…Ø­ØµÙˆÙ„Ø§Øª:** {brand.get('products', 'Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ØµØ±ÙÛŒ')}")
                lines.append(f"- **Ø¯Ø³ØªÙ‡:** {brand.get('category', 'Ù†Ø§Ù…Ø´Ø®Øµ').replace('_', ' ').title()}")
                lines.append(f"- **Ù…Ø®Ø§Ø·Ø¨ Ù‡Ø¯Ù:** {brand.get('target_audience', 'Ù…ØµØ±Ùâ€ŒÚ©Ù†Ù†Ø¯Ú¯Ø§Ù† Ø¹Ù…ÙˆÙ…ÛŒ')}")
                lines.append(f"- **Ø³Ø·Ø­ Ù‚ÛŒÙ…ØªÛŒ:** {brand.get('price_tier', 'Ù†Ø§Ù…Ø´Ø®Øµ').replace('_', ' ').title()}")
                lines.append(f"- **Ù‡Ù…â€ŒØ§ÙØ²Ø§ÛŒÛŒ ÙØ±ÙˆØ´ Ù…ØªÙ‚Ø§Ø¨Ù„:** {synergy}")
                lines.append("")

        brand_family = relationships.get("brand_family", [])
        if brand_family:
            lines.append(f"### Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡ Ú¯Ø³ØªØ±Ø¯Ù‡ Ø¨Ø±Ù†Ø¯ ({len(brand_family)} Ø¨Ø±Ù†Ø¯)")
            lines.append("")
            lines.append("Ø³Ø¨Ø¯ Ú¯Ø³ØªØ±Ø¯Ù‡â€ŒØªØ± Ú¯Ø±ÙˆÙ‡ Ø´Ø§Ù…Ù„:")
            lines.append("")

            # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø±Ú©Øª Ù…Ø§Ø¯Ø±
            by_parent = {}
            for brand in brand_family:
                parent_name = brand.get("parent", "Ù†Ø§Ù…Ø´Ø®Øµ")
                if parent_name not in by_parent:
                    by_parent[parent_name] = []
                by_parent[parent_name].append(brand)

            for parent_name, brands in by_parent.items():
                lines.append(f"**{parent_name}:**")
                for brand in brands[:5]:  # Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù‡ 5 Ø¨Ø±Ù†Ø¯ Ø¯Ø± Ù‡Ø± Ù…Ø§Ø¯Ø±
                    lines.append(f"- {brand.get('name')} ({brand.get('category', 'Ù…ØµØ±ÙÛŒ').replace('_', ' ').title()})")
                lines.append("")

        lines.append("---")
        lines.append("")

        # ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ©
        lines.append("## ğŸ’¡ ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ©")
        lines.append("")

        cross_promo = insights.get("cross_promotion_opportunities", [])
        if cross_promo:
            lines.append(f"### {min(3, len(cross_promo))} ÙØ±ØµØª Ø¨Ø±ØªØ± ØªØ¨Ù„ÛŒØºØ§Øª Ù…ØªÙ‚Ø§Ø¨Ù„")
            lines.append("")

            for i, opp in enumerate(cross_promo[:3], 1):
                priority = opp.get("priority", "medium")
                priority_emoji = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(priority, "âšª")

                lines.append(f"#### {i}. {opp.get('partner_brand')} {priority_emoji}")
                lines.append("")
                lines.append(f"**Ø³Ø·Ø­ Ù‡Ù…â€ŒØ§ÙØ²Ø§ÛŒÛŒ:** {opp.get('synergy_level')}")
                lines.append(f"**Ø§ÙˆÙ„ÙˆÛŒØª:** {priority.upper()}")
                lines.append("")
                lines.append(f"**Ù…ÙÙ‡ÙˆÙ… Ú©Ù…Ù¾ÛŒÙ†:**")
                lines.append(f"{opp.get('campaign_concept')}")
                lines.append("")
                lines.append(f"**Ù…Ø®Ø§Ø·Ø¨ Ù‡Ø¯Ù:** {opp.get('target_audience')}")
                lines.append(f"**Ø¨ÙˆØ¯Ø¬Ù‡ ØªØ®Ù…ÛŒÙ†ÛŒ:** {opp.get('estimated_budget')}")
                lines.append(f"**Ù…Ù†ÙØ¹Øª Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±:** {opp.get('expected_benefit')}")
                lines.append(f"**Ø§Ø¬Ø±Ø§:** Ø³Ø®ØªÛŒ {opp.get('implementation_difficulty', 'Ù…ØªÙˆØ³Ø·').title()}")
                lines.append("")

        lines.append("---")
        lines.append("")

        # Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ù…Ù¾ÛŒÙ†
        lines.append("## ğŸ“… Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ù…Ù¾ÛŒÙ†")
        lines.append("")

        timing = insights.get("campaign_timing", {})

        optimal = timing.get("optimal_periods", [])
        if optimal:
            lines.append("### Ø¯ÙˆØ±Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ú©Ù…Ù¾ÛŒÙ†")
            lines.append("")
            for period in optimal:
                lines.append(f"- **{period}**")
            lines.append("")

        quarterly = timing.get("quarterly_recommendations", {})
        if quarterly:
            lines.append("### ØªÙÚ©ÛŒÚ© ÙØµÙ„ÛŒ")
            lines.append("")
            for quarter, rec in quarterly.items():
                lines.append(f"**{quarter}:** {rec}")
                lines.append("")

        avoid = timing.get("avoid_periods", [])
        if avoid:
            lines.append("### Ø¯ÙˆØ±Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬ØªÙ†Ø§Ø¨")
            lines.append("")
            for period in avoid:
                lines.append(f"- {period}")
            lines.append("")

        seasonal = timing.get("seasonal_considerations")
        if seasonal:
            lines.append(f"**Ø²Ù…ÛŒÙ†Ù‡ ÙØ±Ù‡Ù†Ú¯ÛŒ:** {seasonal}")
            lines.append("")

        lines.append("---")
        lines.append("")

        # Ø¨ÙˆØ¯Ø¬Ù‡ Ùˆ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§
        lines.append("## ğŸ’° ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨ÙˆØ¯Ø¬Ù‡ Ùˆ Ú©Ø§Ù†Ø§Ù„")
        lines.append("")

        budget = insights.get("budget_recommendations", {})
        if budget:
            lines.append("### Ø¨ÙˆØ¯Ø¬Ù‡ ØªÙˆØµÛŒÙ‡â€ŒØ´Ø¯Ù‡")
            lines.append("")
            if budget.get("estimated_range_tomans"):
                lines.append(f"- **Ø¨ÙˆØ¯Ø¬Ù‡ Ø³Ø§Ù„Ø§Ù†Ù‡:** {budget['estimated_range_tomans']}")
            if budget.get("estimated_range_usd"):
                lines.append(f"- **Ù…Ø¹Ø§Ø¯Ù„ Ø¯Ù„Ø§Ø±:** {budget['estimated_range_usd']}")
            if budget.get("roi_expectations"):
                lines.append(f"- **Ø¨Ø§Ø²Ø¯Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±:** {budget['roi_expectations']}")
            lines.append("")

            if budget.get("rationale"):
                lines.append(f"**Ø¯Ù„ÛŒÙ„:** {budget['rationale']}")
                lines.append("")

        allocation = budget.get("allocation_by_channel", {})
        if allocation:
            lines.append("### ØªØ®ØµÛŒØµ Ú©Ø§Ù†Ø§Ù„")
            lines.append("")
            lines.append("| Ú©Ø§Ù†Ø§Ù„ | ØªØ®ØµÛŒØµ |")
            lines.append("|---------|------------|")
            for channel, percent in allocation.items():
                lines.append(f"| {channel} | {percent} |")
            lines.append("")

        channel_recs = insights.get("channel_recommendations", [])
        if channel_recs:
            lines.append("### Ø¬Ø²Ø¦ÛŒØ§Øª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ú©Ø§Ù†Ø§Ù„")
            lines.append("")

            for ch in channel_recs:
                priority = ch.get("priority", "medium")
                priority_badge = {"high": "ğŸ”´ Ø¨Ø§Ù„Ø§", "medium": "ğŸŸ¡ Ù…ØªÙˆØ³Ø·", "low": "ğŸŸ¢ Ù¾Ø§ÛŒÛŒÙ†"}.get(priority, "âšª Ù†Ø§Ù…Ø´Ø®Øµ")

                lines.append(f"#### {ch.get('channel')} - {priority_badge}")
                lines.append("")
                lines.append(f"**Ø¯Ù„ÛŒÙ„:** {ch.get('rationale')}")
                lines.append(f"**Ù†ÙˆØ¹ Ù…Ø­ØªÙˆØ§:** {ch.get('content_type')}")
                lines.append(f"**ØªØ®ØµÛŒØµ Ø¨ÙˆØ¯Ø¬Ù‡:** {ch.get('budget_allocation')}")
                lines.append("")

        lines.append("---")
        lines.append("")

        # Ø¬Ù‡Øªâ€ŒÚ¯ÛŒØ±ÛŒ Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡
        lines.append("## ğŸ¨ Ø¬Ù‡Øªâ€ŒÚ¯ÛŒØ±ÛŒ Ø®Ù„Ø§Ù‚ÛŒØª")
        lines.append("")

        creative = insights.get("creative_direction", {})

        messages = creative.get("key_messages", [])
        if messages:
            lines.append("### Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ù†Ø¯")
            lines.append("")
            for msg in messages:
                lines.append(f"- {msg}")
            lines.append("")

        if creative.get("tone_and_style"):
            lines.append(f"**Ù„Ø­Ù† Ùˆ Ø³Ø¨Ú©:** {creative['tone_and_style']}")
            lines.append("")

        if creative.get("visual_recommendations"):
            lines.append(f"**Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¨ØµØ±ÛŒ:** {creative['visual_recommendations']}")
            lines.append("")

        if creative.get("cultural_considerations"):
            lines.append(f"**Ù…Ù„Ø§Ø­Ø¸Ø§Øª ÙØ±Ù‡Ù†Ú¯ÛŒ:** {creative['cultural_considerations']}")
            lines.append("")

        hashtags = creative.get("hashtag_strategy", [])
        if hashtags:
            lines.append("**Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù‡Ø´ØªÚ¯:**")
            lines.append("")
            lines.append(" ".join(hashtags))
            lines.append("")

        themes = creative.get("content_themes", [])
        if themes:
            lines.append("### ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø­ØªÙˆØ§ÛŒÛŒ")
            lines.append("")
            for theme in themes:
                lines.append(f"- {theme}")
            lines.append("")

        if creative.get("storytelling_angle"):
            lines.append(f"**Ø¯Ø§Ø³ØªØ§Ù† Ø¨Ø±Ù†Ø¯:** {creative['storytelling_angle']}")
            lines.append("")

        lines.append("---")
        lines.append("")

        # Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…ÙˆÙÙ‚ÛŒØª
        lines.append("## ğŸ“ˆ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…ÙˆÙÙ‚ÛŒØª Ùˆ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ")
        lines.append("")

        metrics = insights.get("success_metrics", {})

        kpis = metrics.get("primary_kpis", [])
        if kpis:
            lines.append("### Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø§ØµÙ„ÛŒ")
            lines.append("")
            for kpi in kpis:
                lines.append(f"- {kpi}")
            lines.append("")

        if metrics.get("measurement_approach"):
            lines.append(f"**Ø±ÙˆÛŒÚ©Ø±Ø¯ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ:** {metrics['measurement_approach']}")
            lines.append("")

        if metrics.get("benchmarks"):
            lines.append(f"**Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡:** {metrics['benchmarks']}")
            lines.append("")

        lines.append("---")
        lines.append("")

        # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø±Ù‚Ø§Ø¨ØªÛŒ
        lines.append("## ğŸ¯ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø±Ù‚Ø§Ø¨ØªÛŒ")
        lines.append("")

        competitive = insights.get("competitive_strategy", {})

        if competitive.get("positioning"):
            lines.append(f"**Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÛŒØ§Ø¨ÛŒ:** {competitive['positioning']}")
            lines.append("")

        diff_points = competitive.get("differentiation_points", [])
        if diff_points:
            lines.append("### Ù†Ù‚Ø§Ø· ØªÙ…Ø§ÛŒØ²")
            lines.append("")
            for point in diff_points:
                lines.append(f"- {point}")
            lines.append("")

        advantages = competitive.get("competitive_advantages_to_highlight", [])
        if advantages:
            lines.append("### Ù…Ø²Ø§ÛŒØ§ÛŒ Ø±Ù‚Ø§Ø¨ØªÛŒ")
            lines.append("")
            for adv in advantages:
                lines.append(f"- {adv}")
            lines.append("")

        pillars = competitive.get("messaging_pillars", [])
        if pillars:
            lines.append("### Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ§Ù…â€ŒØ±Ø³Ø§Ù†ÛŒ")
            lines.append("")
            for pillar in pillars:
                lines.append(f"1. {pillar}")
            lines.append("")

        lines.append("---")
        lines.append("")

        # Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ
        lines.append("## ğŸ¬ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ùˆ Ù…Ø±Ø§Ø­Ù„ Ø¨Ø¹Ø¯ÛŒ")
        lines.append("")
        lines.append(f"Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø§Ø² {brand_name} ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø´Ø¯ Ø±Ø§ Ø¢Ø´Ú©Ø§Ø± Ù…ÛŒâ€ŒØ³Ø§Ø²Ø¯ ")
        lines.append("Ø§Ø² Ø·Ø±ÛŒÙ‚ Ù…Ø´Ø§Ø±Ú©Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ© Ø¨Ø±Ù†Ø¯ØŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ù‡Ø¯ÙÙ…Ù†Ø¯ Ú©Ù…Ù¾ÛŒÙ† Ùˆ Ø±ÙˆÛŒÚ©Ø±Ø¯Ù‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±ÛŒØ§Ø¨ÛŒ Ú†Ù†Ø¯Ú©Ø§Ù†Ø§Ù„Ù‡.")
        lines.append("")
        lines.append("**Ø§Ù‚Ø¯Ø§Ù…Ø§Øª ÙÙˆØ±ÛŒ ØªÙˆØµÛŒÙ‡â€ŒØ´Ø¯Ù‡:**")
        lines.append("")
        lines.append("1. Ø¢ØºØ§Ø² Ù…Ø°Ø§Ú©Ø±Ø§Øª Ø¨Ø§ 3 Ø¨Ø±Ù†Ø¯ Ø®ÙˆØ§Ù‡Ø± Ø¨Ø±ØªØ± Ø¨Ø±Ø§ÛŒ Ú©Ù…Ù¾ÛŒÙ†â€ŒÙ‡Ø§ÛŒ ØªØ¨Ù„ÛŒØºØ§Øª Ù…ØªÙ‚Ø§Ø¨Ù„")
        lines.append("2. ØªÙˆØ³Ø¹Ù‡ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙØµÛŒÙ„ÛŒ Ú©Ù…Ù¾ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ±Ù‡â€ŒÙ‡Ø§ÛŒ ÙØµÙ„ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡")
        lines.append("3. ØªØ®ØµÛŒØµ Ø¨ÙˆØ¯Ø¬Ù‡ Ø¨Ø§Ø²Ø§Ø±ÛŒØ§Ø¨ÛŒ Ø·Ø¨Ù‚ ØªÙˆØ²ÛŒØ¹ Ú©Ø§Ù†Ø§Ù„ ØªÙˆØµÛŒÙ‡â€ŒØ´Ø¯Ù‡")
        lines.append("4. Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø²ÛŒØ±Ø³Ø§Ø®Øª Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ù†Ø¬Ø´ Ú©Ù…Ù¾ÛŒÙ†")
        lines.append("5. Ø¢ØºØ§Ø² ØªÙˆØ³Ø¹Ù‡ Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡ Ù‡Ù…Ø±Ø§Ø³ØªØ§ Ø¨Ø§ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ§Ù…â€ŒØ±Ø³Ø§Ù†ÛŒ Ø¨Ø±Ù†Ø¯")
        lines.append("")
        lines.append("---")
        lines.append("")
        lines.append(f"*Ú¯Ø²Ø§Ø±Ø´ ØªÙˆÙ„ÛŒØ¯Ø´Ø¯Ù‡ ØªÙˆØ³Ø· Ø¹Ø§Ù…Ù„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ù†Ø¯ Ø¯Ø± {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")

        # Write with UTF-8 encoding
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines))

        return output_path

    def _generate_product_catalog(self, state: Dict, output_dir: Path, timestamp: str) -> Path:
        """Generate complete product catalog JSON - 7_product_catalog.json"""
        output_path = output_dir / "7_product_catalog.json"

        brand_name = state["brand_name"]
        product_catalog = state.get("product_catalog", {})
        relationships = state.get("relationships", {})
        categorization = state.get("categorization", {})

        # Build comprehensive catalog
        catalog_output = {
            "brand_intelligence_product_catalog": {
                "brand_name": brand_name,
                "generated_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "report_id": timestamp,
                "extraction_method": product_catalog.get("extraction_method", "automated"),
                "data_quality": "comprehensive" if product_catalog.get("total_products", 0) > 0 else "limited"
            },
            "catalog_summary": {
                "total_products": product_catalog.get("total_products", 0),
                "total_therapeutic_areas": len(product_catalog.get("therapeutic_areas", [])),
                "total_categories": len(product_catalog.get("categories", {})),
                "product_lines": product_catalog.get("product_lines", [])
            },
            "therapeutic_areas": product_catalog.get("therapeutic_areas", []),
            "product_categories": product_catalog.get("categories", {}),
            "complete_product_list": product_catalog.get("products", []),
            "services_list": product_catalog.get("services", []),  # Include services
            "market_intelligence": product_catalog.get("market_intelligence", {}),
            "metadata": product_catalog.get("metadata", {}),  # Include metadata (counselors count, etc.)
            "corporate_relationships": {
                "parent_company": relationships.get("parent_company", {}).get("name", "Unknown"),
                "ultimate_parent": relationships.get("ultimate_parent", {}).get("name_fa", "Unknown"),
                "manufacturing_subsidiaries": self._extract_manufacturing_subsidiaries(relationships),
                "marketing_distribution_role": self._extract_marketing_role(brand_name, relationships)
            },
            "industry_classification": {
                "primary_industry": categorization.get("primary_industry", {}),
                "sub_industries": categorization.get("sub_industries", []),
                "business_model": categorization.get("business_model", "Unknown")
            }
        }

        # Add product statistics if available
        if "product_statistics" in product_catalog:
            catalog_output["product_statistics"] = product_catalog["product_statistics"]

        # Write with UTF-8 encoding
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(catalog_output, f, ensure_ascii=False, indent=2)

        return output_path

    def _extract_manufacturing_subsidiaries(self, relationships: Dict) -> List[str]:
        """Extract manufacturing subsidiaries from relationships."""
        subs = []
        for brand in relationships.get("sister_brands", []):
            if "manufacturing" in brand.get("products", "").lower() or "manufacturer" in brand.get("role", "").lower():
                subs.append(brand.get("name"))
        return subs if subs else ["Unknown"]

    def _extract_marketing_role(self, brand_name: str, relationships: Dict) -> Dict[str, Any]:
        """Determine if this brand is a marketing/distribution entity."""
        # Check if brand name suggests marketing role
        marketing_keywords = ["pharmed", "distribution", "marketing", "pakhsh", "Ù¾Ø®Ø´"]

        is_marketing_entity = any(kw in brand_name.lower() for kw in marketing_keywords)

        if is_marketing_entity:
            return {
                "role": "Marketing & Distribution",
                "handles_brands": [b.get("name") for b in relationships.get("sister_brands", [])],
                "description": f"{brand_name} handles marketing and distribution for group brands"
            }
        else:
            return {
                "role": "Manufacturing/Product Brand",
                "description": f"{brand_name} is a product/manufacturing brand"
            }

    def _generate_all_data_aggregated(
        self,
        state: Dict,
        output_dir: Path,
        timestamp: str,
        output_files: Dict[str, str]
    ) -> Path:
        """Generate aggregated file containing ALL data from all other files.

        This creates a comprehensive text file that includes:
        - All JSON files (formatted as readable text)
        - All CSV files (formatted as tables)
        - All TXT files
        - All MD files

        Args:
            state: Workflow state
            output_dir: Output directory path
            timestamp: Timestamp string
            output_files: Dictionary of already generated file paths

        Returns:
            Path to generated aggregated file
        """
        output_path = output_dir / "7_all_data_aggregated.txt"

        brand_name = state["brand_name"]

        lines = []
        lines.append("=" * 100)
        lines.append("ØªØ¬Ù…ÛŒØ¹ Ú©Ø§Ù…Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ - ØªØ±Ú©ÛŒØ¨ ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§")
        lines.append("=" * 100)
        lines.append(f"Ø¨Ø±Ù†Ø¯: {brand_name}")
        lines.append(f"ØªØ§Ø±ÛŒØ® ØªÙˆÙ„ÛŒØ¯: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"Ø´Ù†Ø§Ø³Ù‡ Ú¯Ø²Ø§Ø±Ø´: {timestamp}")
        lines.append("")
        lines.append("Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø´Ø§Ù…Ù„ ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø§Ø³Øª:")
        lines.append("  - 0_complete_master_report.txt")
        lines.append("  - 1_brand_profile.json")
        lines.append("  - 2_strategic_insights.json")
        lines.append("  - 3_brands_database.csv")
        lines.append("  - 4_embedding_ready.txt")
        lines.append("  - 5_financial_intelligence.json")
        lines.append("  - 6_executive_summary.md")
        lines.append("  - 7_product_catalog.json")
        lines.append("=" * 100)
        lines.append("")
        lines.append("")

        # Ø¨Ø®Ø´ Û±: Ú¯Ø²Ø§Ø±Ø´ Ø¬Ø§Ù…Ø¹
        lines.append("#" * 100)
        lines.append("# ÙØ§ÛŒÙ„ Û°: Ú¯Ø²Ø§Ø±Ø´ Ø¬Ø§Ù…Ø¹ (TXT)")
        lines.append("#" * 100)
        lines.append("")

        master_report_path = output_files.get("master_report")
        if master_report_path and Path(master_report_path).exists():
            with open(master_report_path, 'r', encoding='utf-8') as f:
                lines.append(f.read())
        else:
            lines.append("[Ú¯Ø²Ø§Ø±Ø´ Ø¬Ø§Ù…Ø¹ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª]")

        lines.append("")
        lines.append("")

        # Ø¨Ø®Ø´ Û²: Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø¨Ø±Ù†Ø¯ JSON
        lines.append("#" * 100)
        lines.append("# ÙØ§ÛŒÙ„ Û±: Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø¨Ø±Ù†Ø¯ (JSON)")
        lines.append("#" * 100)
        lines.append("")

        profile_path = output_files.get("brand_profile")
        if profile_path and Path(profile_path).exists():
            with open(profile_path, 'r', encoding='utf-8') as f:
                profile_data = json.load(f)

            lines.append("Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø¨Ø±Ù†Ø¯ - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡")
            lines.append("-" * 100)
            lines.append("")

            # Full JSON
            lines.append("JSON Ú©Ø§Ù…Ù„:")
            lines.append(json.dumps(profile_data, ensure_ascii=False, indent=2))
        else:
            lines.append("[Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø¨Ø±Ù†Ø¯ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª]")

        lines.append("")
        lines.append("")

        # Ø¨Ø®Ø´ Û³: Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ© JSON
        lines.append("#" * 100)
        lines.append("# ÙØ§ÛŒÙ„ Û²: Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ© (JSON)")
        lines.append("#" * 100)
        lines.append("")

        insights_path = output_files.get("strategic_insights")
        if insights_path and Path(insights_path).exists():
            with open(insights_path, 'r', encoding='utf-8') as f:
                insights_data = json.load(f)

            lines.append("Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ© - ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø§Ù…Ø¹")
            lines.append("-" * 100)
            lines.append("")
            lines.append("JSON Ú©Ø§Ù…Ù„:")
            lines.append(json.dumps(insights_data, ensure_ascii=False, indent=2))
        else:
            lines.append("[Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ© Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª]")

        lines.append("")
        lines.append("")

        # Ø¨Ø®Ø´ Û´: Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ù†Ø¯Ù‡Ø§ CSV
        lines.append("#" * 100)
        lines.append("# ÙØ§ÛŒÙ„ Û³: Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ù†Ø¯Ù‡Ø§ (CSV)")
        lines.append("#" * 100)
        lines.append("")

        csv_path = output_files.get("brands_database")
        if csv_path and Path(csv_path).exists():
            with open(csv_path, 'r', encoding='utf-8') as f:
                csv_content = f.read()

            lines.append("Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ù†Ø¯Ù‡Ø§ - Ø¬Ø¯ÙˆÙ„ Ø¨Ø±Ù†Ø¯Ù‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·")
            lines.append("-" * 100)
            lines.append("")
            lines.append(csv_content)
        else:
            lines.append("[Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ù†Ø¯Ù‡Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª]")

        lines.append("")
        lines.append("")

        # Ø¨Ø®Ø´ Ûµ: Ù…ØªÙ† Ø¢Ù…Ø§Ø¯Ù‡ Embedding
        lines.append("#" * 100)
        lines.append("# ÙØ§ÛŒÙ„ Û´: Ù…ØªÙ† Ø¢Ù…Ø§Ø¯Ù‡ Embedding")
        lines.append("#" * 100)
        lines.append("")

        embedding_path = output_files.get("embedding_ready")
        if embedding_path and Path(embedding_path).exists():
            with open(embedding_path, 'r', encoding='utf-8') as f:
                lines.append(f.read())
        else:
            lines.append("[Ù…ØªÙ† embedding Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª]")

        lines.append("")
        lines.append("")

        # Ø¨Ø®Ø´ Û¶: Ù‡ÙˆØ´Ù…Ù†Ø¯ÛŒ Ù…Ø§Ù„ÛŒ JSON
        lines.append("#" * 100)
        lines.append("# ÙØ§ÛŒÙ„ Ûµ: Ù‡ÙˆØ´Ù…Ù†Ø¯ÛŒ Ù…Ø§Ù„ÛŒ (JSON)")
        lines.append("#" * 100)
        lines.append("")

        financial_path = output_files.get("financial_intelligence")
        if financial_path and Path(financial_path).exists():
            with open(financial_path, 'r', encoding='utf-8') as f:
                financial_data = json.load(f)

            lines.append("Ù‡ÙˆØ´Ù…Ù†Ø¯ÛŒ Ù…Ø§Ù„ÛŒ - ØªØ­Ù„ÛŒÙ„ Ø´Ø±Ú©Øª Ù…Ø§Ø¯Ø±")
            lines.append("-" * 100)
            lines.append("")
            lines.append("JSON Ú©Ø§Ù…Ù„:")
            lines.append(json.dumps(financial_data, ensure_ascii=False, indent=2))
        else:
            lines.append("[Ù‡ÙˆØ´Ù…Ù†Ø¯ÛŒ Ù…Ø§Ù„ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª]")

        lines.append("")
        lines.append("")

        # Ø¨Ø®Ø´ Û·: Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ Markdown
        lines.append("#" * 100)
        lines.append("# ÙØ§ÛŒÙ„ Û¶: Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ (MARKDOWN)")
        lines.append("#" * 100)
        lines.append("")

        summary_path = output_files.get("executive_summary")
        if summary_path and Path(summary_path).exists():
            with open(summary_path, 'r', encoding='utf-8') as f:
                lines.append(f.read())
        else:
            lines.append("[Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª]")

        lines.append("")
        lines.append("")

        # Ø¨Ø®Ø´ Û¸: Ú©Ø§ØªØ§Ù„ÙˆÚ¯ Ù…Ø­ØµÙˆÙ„Ø§Øª
        lines.append("#" * 100)
        lines.append("# ÙØ§ÛŒÙ„ Û·: Ú©Ø§ØªØ§Ù„ÙˆÚ¯ Ú©Ø§Ù…Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª (JSON)")
        lines.append("#" * 100)
        lines.append("")

        product_catalog_path = output_files.get("product_catalog")
        if product_catalog_path and Path(product_catalog_path).exists():
            with open(product_catalog_path, 'r', encoding='utf-8') as f:
                catalog_data = json.load(f)

            lines.append("Ú©Ø§ØªØ§Ù„ÙˆÚ¯ Ú©Ø§Ù…Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª")
            lines.append("-" * 100)
            lines.append("")
            lines.append("JSON Ú©Ø§Ù…Ù„:")
            lines.append(json.dumps(catalog_data, ensure_ascii=False, indent=2))
        else:
            lines.append("[Ú©Ø§ØªØ§Ù„ÙˆÚ¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª]")

        lines.append("")
        lines.append("")
        lines.append("=" * 100)
        lines.append("Ù¾Ø§ÛŒØ§Ù† ÙØ§ÛŒÙ„ ØªØ¬Ù…ÛŒØ¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
        lines.append("=" * 100)
        lines.append(f"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø¨Ø®Ø´â€ŒÙ‡Ø§: ØªØ±Ú©ÛŒØ¨ 9 ÙØ§ÛŒÙ„")
        lines.append(f"ØªØ§Ø±ÛŒØ® ØªÙˆÙ„ÛŒØ¯: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("=" * 100)

        # Write with UTF-8 encoding
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines))

        return output_path
